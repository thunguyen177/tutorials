from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers

# Initialize a tokenizer with BPE
tokenizer = Tokenizer(models.BPE())
tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()
tokenizer.decoder = decoders.ByteLevel()

# Training the tokenizer
trainer = trainers.BpeTrainer(vocab_size=1000, min_frequency=2)
tokenizer.train(["path/to/your/text/file.txt"], trainer)

# Encoding text
encoded = tokenizer.encode("Hello, world!")
print("Tokens:", encoded.tokens)

# Decoding text
decoded = tokenizer.decode(encoded.ids)
print("Decoded text:", decoded)